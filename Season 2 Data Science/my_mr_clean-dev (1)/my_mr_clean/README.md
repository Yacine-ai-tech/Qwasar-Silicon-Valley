# Welcome to My Mr Clean


## Task
The goal of this project is to analyze and visualize the most frequently used words in a given Wikipedia article. The main challenge is to fetch the article content, clean it by removing HTML tags and citations, tokenize the text, count the frequency of each word, and visualize the most common words while filtering out common stop words.

## Description
This project solves the problem by:

Fetching the introductory content of a specified Wikipedia article using the Wikipedia API.
Cleaning the content to remove HTML tags and citations.
Tokenizing the cleaned content into individual words.
Counting the frequency of each word in the tokenized content.
Filtering out common stop words to focus on the more meaningful words.
Visualizing the most frequent words using a horizontal bar plot.

## Installation
To install and run this project, ensure you have Python installed. Then, install the required libraries:

pip install requests matplotlib seaborn

## Usage

The project consists of several functions to achieve the tasks outlined. Here is a brief overview of how to use it:

Fetch the article content,Tokenize the cleaned content,Count the frequency of tokens,Plot the most frequent tokens,Remove stop words and replot

### The Core Team


<span><i>Made at <a href='https://qwasar.io'>Qwasar SV -- Software Engineering School</a></i></span>
<span><img alt='Qwasar SV -- Software Engineering School's Logo' src='https://storage.googleapis.com/qwasar-public/qwasar-logo_50x50.png' width='20px' /></span>
